{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d7e0347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wikipedia\n",
    "import psycopg2\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "from typing import Optional\n",
    "from langchain.tools import Tool\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "_ = load_dotenv(find_dotenv('src/.env'))  # Read local .env file\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "DATABASE_URL = os.environ[\"DATABASE_URL\"]\n",
    "SERPAPI_KEY = os.environ[\"SERPAPI_KEY\"]  # For Google search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbcfaf99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Run the API on localhost\\nif __name__ == \"__main__\":\\n    uvicorn.run(app, host=\"127.0.0.1\", port=8000)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import wikipedia\n",
    "import psycopg2\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import uvicorn\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "from typing import Optional\n",
    "from langchain.tools import Tool\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "_ = load_dotenv(find_dotenv())  # Read local .env file\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "DATABASE_URL = os.environ[\"DATABASE_URL\"]\n",
    "SERPAPI_KEY = os.environ[\"SERPAPI_KEY\"]  # For Google search\n",
    "\n",
    "# Initialize FastAPI\n",
    "app = FastAPI()\n",
    "\n",
    "# Database connection\n",
    "def get_db_connection():\n",
    "    return psycopg2.connect(DATABASE_URL)\n",
    "\n",
    "# Input model\n",
    "class QueryRequest(BaseModel):\n",
    "    query: str\n",
    "    location: Optional[str] = None  # For queries like \"near me\"\n",
    "\n",
    "# Dictionary to store chat history\n",
    "global chat_history\n",
    "chat_history = []\n",
    "\n",
    "# Function to maintain chat history\n",
    "def update_chat_history(user_query: str, bot_response: str):\n",
    "    global chat_history\n",
    "    \n",
    "    # Reset chat history if conversation goes off-topic\n",
    "    if classify_query_with_llm(user_query) == \"Irrelevant\":\n",
    "        chat_history = []\n",
    "\n",
    "    chat_history.append({\"user\": user_query, \"bot\": bot_response})\n",
    "\n",
    "# Function to generate SQL query using LLM\n",
    "def generate_sql_query(user_query: str):\n",
    "    prompt = f\"\"\"\n",
    "    You are an AI trained to generate SQL queries for a PostgreSQL database based on user input.\n",
    "    The database has a table named `restaurant_menu` with the following columns:\n",
    "    - `restaurant_name` (VARCHAR)\n",
    "    - `menu_category` (VARCHAR)\n",
    "    - `item_id` (INTEGER)\n",
    "    - `menu_item` (VARCHAR)\n",
    "    - `menu_description` (TEXT)\n",
    "    - `ingredient_name` (VARCHAR)\n",
    "    - `confidence` (FLOAT)\n",
    "    - `categories` (VARCHAR)\n",
    "    - `address1` (TEXT)\n",
    "    - `city` (VARCHAR)\n",
    "    - `zip_code` (VARCHAR)\n",
    "    - `country` (VARCHAR)\n",
    "    - `state` (VARCHAR)\n",
    "    - `rating` (VARCHAR)\n",
    "    - `review_count` (VARCHAR)\n",
    "    - `price` (VARCHAR)\n",
    "\n",
    "    Convert the following user query into a valid SQL query for the `restaurant_menu` table:\n",
    "    \"{user_query}\"\n",
    "\n",
    "    Only return the SQL query, no extra explanations, and do not include any code formatting markers.\n",
    "    Remember review_count, rating, and price columns are varchar. Perform cast conversion where necessary.\n",
    "    Don't forget to use DISTINCT as there are many duplicate restaurant names, ingredients, menu items etc.\n",
    "    Everything in the database is lower case, so remember to lowercase query values.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=100,\n",
    "    )\n",
    "    \n",
    "    return response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "\n",
    "# Function to execute SQL query\n",
    "def execute_sql_query(sql: str):\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        cursor.execute(sql)\n",
    "        results = cursor.fetchall()\n",
    "        if not results:\n",
    "            return \"No matching results found.\"\n",
    "        formatted_results = \"\\n\".join([\", \".join(map(str, row)) for row in results])\n",
    "        return formatted_results\n",
    "    except Exception as e:\n",
    "        return f\"Error executing query: {e}\"\n",
    "    finally:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "# Function to query restaurant database\n",
    "def query_restaurant_db(query: str, location: Optional[str]):\n",
    "    sql_query = generate_sql_query(query)\n",
    "    return execute_sql_query(sql_query)\n",
    "\n",
    "# Wikipedia search function\n",
    "def search_wikipedia(query: str):\n",
    "    try:\n",
    "        return wikipedia.summary(query, sentences=2)\n",
    "    except wikipedia.exceptions.PageError:\n",
    "        return \"No relevant Wikipedia article found.\"\n",
    "    except wikipedia.exceptions.DisambiguationError as e:\n",
    "        return f\"Did you mean: {', '.join(e.options[:5])}?\"\n",
    "\n",
    "# Google Search using SerpAPI\n",
    "def search_google(query: str):\n",
    "    google_search = SerpAPIWrapper(serpapi_api_key=SERPAPI_KEY)\n",
    "    return google_search.run(query)\n",
    "\n",
    "# LLM response function\n",
    "def generate_response(prompt: str):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful food assistant.\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "# Helper function to classify query using LLM\n",
    "def classify_query_with_llm(query: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Classify the following query into one of the categories: Greeting, SQL, Wikipedia, GoogleSearch, Irrelevant.\n",
    "    \n",
    "    Query: {query}\n",
    "    Categories:\n",
    "    - Greeting: Greetings like \"Hello\", \"Hi\", \"Hey\", \"How are you?\", \"Good morning\", \"Good evening\", \"What can you do\".\n",
    "    - SQL: Queries that involve database searches, like finding restaurants, prices, or ratings.\n",
    "    - Wikipedia: Queries related to food items like sushi, food ingredients, cuisine history, nutrition, or similar background information.\n",
    "    - GoogleSearch: Queries asking for trending, popular, or recent food-related information, such as reviews or new restaurants.\n",
    "    - Irrelevant: If the query is about politics, violence, technology, sports, general knowledge, or anything unrelated to food or restaurants.\n",
    "    \n",
    "    Return only one of the categories: \"Greeting\", \"SQL\", \"Wikipedia\", \"GoogleSearch\", \"Irrelevant\" as string. Only the words.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=20,\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "\n",
    "# Helper function: return recent chat history as a string.\n",
    "# It takes the last two Q/A pairs and trims the string if it exceeds max_length.\n",
    "def get_recent_history(max_entries=2, max_length=250) -> str:\n",
    "    recent_entries = chat_history[-max_entries:]\n",
    "    history_str = \"\\n\".join([f\"User: {entry['user']}\\nBot: {entry['bot']}\" for entry in recent_entries])\n",
    "    if len(history_str) > max_length:\n",
    "        history_str = history_str[-max_length:]\n",
    "    return history_str\n",
    "\n",
    "@app.post(\"/chat/\")\n",
    "def chatbot(request: QueryRequest):\n",
    "    query = request.query.lower()\n",
    "    query_type = classify_query_with_llm(query)\n",
    "    recent_history = get_recent_history()  # Recent two interactions, trimmed\n",
    "\n",
    "    if query_type == \"Greeting\":\n",
    "        bot_response = \"Hello! Iâ€™m your restaurant and food assistant. You can ask me about restaurants, menus, food history, or reviews!\"\n",
    "    elif query_type == \"SQL\":\n",
    "        db_response = query_restaurant_db(query, request.location)\n",
    "        full_prompt = (f\"Chat history:\\n{recent_history}\\n\"\n",
    "                       f\"User asked: {query}.\\nDatabase says:\\n{db_response}\")\n",
    "        bot_response = generate_response(full_prompt)\n",
    "    elif query_type == \"Wikipedia\":\n",
    "        # Combine recent history with current query, then trim to a safe limit (e.g. 200 chars)\n",
    "        combined_query = f\"{recent_history} {query}\"\n",
    "        if len(combined_query) > 300:\n",
    "            wiki_query = combined_query[-300:]\n",
    "        else:\n",
    "            wiki_query = combined_query\n",
    "        wiki_info = search_wikipedia(wiki_query)\n",
    "        full_prompt = (f\"Chat history:\\n{recent_history}\\n\"\n",
    "                       f\"User asked: {query}.\\nWikipedia info:\\n{wiki_info}\")\n",
    "        bot_response = generate_response(full_prompt)\n",
    "    elif query_type == \"GoogleSearch\":\n",
    "        combined_query = f\"{recent_history} {query}\"\n",
    "        if len(combined_query) > 300:\n",
    "            web_query = combined_query[-300:]\n",
    "        else:\n",
    "            web_query = combined_query\n",
    "        web_info = search_google(web_query)\n",
    "        full_prompt = (f\"Chat history:\\n{recent_history}\\n\"\n",
    "                       f\"User asked: {query}.\\nWeb search results:\\n{web_info}\")\n",
    "        bot_response = generate_response(full_prompt)\n",
    "    else:\n",
    "        bot_response = \"I can only answer food-related or restaurant queries.\"\n",
    "    \n",
    "    update_chat_history(query, bot_response)\n",
    "    \n",
    "    return {\"response\": bot_response}\n",
    "\n",
    "'''\n",
    "# Run the API on localhost\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(app, host=\"127.0.0.1\", port=8000)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "050e1a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT COUNT(DISTINCT restaurant_name) \n",
      "FROM restaurant_menu \n",
      "WHERE city = 'san francisco' \n",
      "AND rating::FLOAT > 4.5;\n"
     ]
    }
   ],
   "source": [
    "# Test generate_sql_query function\n",
    "user_query = \"Find the number of best restaurants in San Francisco with a rating greater than 4.5\"\n",
    "sql_query = generate_sql_query(user_query)\n",
    "print(sql_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55f111fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "response = execute_sql_query(sql_query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c679a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT DISTINCT restaurant_name FROM restaurant_menu;\n"
     ]
    }
   ],
   "source": [
    "# Test generate_sql_query function\n",
    "user_query = \"List all the restaurants in the database\"\n",
    "sql_query = generate_sql_query(user_query)\n",
    "print(sql_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c2c77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = execute_sql_query(sql_query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd16984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test search_wikipedia function\n",
    "wiki_query = \"Italian cuisine\"\n",
    "wiki_response = search_wikipedia(wiki_query)\n",
    "print(wiki_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fbac51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test generate_response function\n",
    "prompt = \"What are the benefits of a vegan diet?\"\n",
    "response = generate_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b8f942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate FastAPI POST request for chatbot function\n",
    "from pydantic import BaseModel\n",
    "from typing import Optional\n",
    "\n",
    "# Recreate the QueryRequest model (if not already imported)\n",
    "class QueryRequest(BaseModel):\n",
    "    query: str\n",
    "    location: Optional[str] = None\n",
    "    session_id: Optional[str] = None  # Make session_id optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7e21d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'I found that there are 94 best restaurants in San Francisco with a rating greater than 4. Would you like more information on any specific restaurant or cuisine in San Francisco?'}\n"
     ]
    }
   ],
   "source": [
    "# Test the chatbot function\n",
    "request = QueryRequest(query=\"Find the number of best restaurants in San Francisco with a rating greater than 4\")\n",
    "chatbot_response = chatbot(request)\n",
    "print(chatbot_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43525e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the chatbot function\n",
    "request = QueryRequest(query=\"Can you tell me about Italian Cuisine?\")\n",
    "chatbot_response = chatbot(request)\n",
    "print(chatbot_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fda577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the chatbot function\n",
    "request = QueryRequest(query=\"What is the history of pizza, and which restaurants in my area are known for it?\")\n",
    "chatbot_response = chatbot(request)\n",
    "print(chatbot_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3a7728",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = QueryRequest(query=\"Can you tell me its ingredients?\")\n",
    "chatbot_response = chatbot(request)\n",
    "print(chatbot_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2745ac-aadc-41e9-8b37-4ca003dfc0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880279d3-4bb6-4d31-8970-787a46774088",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = QueryRequest(query=\"What are the best restaurants selling that in Boston?\")\n",
    "chatbot_response = chatbot(request)\n",
    "print(chatbot_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aefb724-bd87-425c-840e-6ef50bc26e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wikipedia\n",
    "import psycopg2\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import uvicorn\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "from typing import Optional\n",
    "from langchain.tools import Tool\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "_ = load_dotenv(find_dotenv())  # Read local .env file\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "DATABASE_URL = os.environ[\"DATABASE_URL\"]\n",
    "SERPAPI_KEY = os.environ[\"SERPAPI_KEY\"]  # For Google search\n",
    "\n",
    "# Initialize FastAPI\n",
    "app = FastAPI()\n",
    "\n",
    "# Database connection\n",
    "def get_db_connection():\n",
    "    return psycopg2.connect(DATABASE_URL)\n",
    "\n",
    "# Input model\n",
    "class QueryRequest(BaseModel):\n",
    "    query: str\n",
    "    location: Optional[str] = None  # For queries like \"near me\"\n",
    "\n",
    "# Dictionary to store chat history\n",
    "global chat_history\n",
    "chat_history = []\n",
    "\n",
    "# Function to maintain chat history\n",
    "def update_chat_history(user_query: str, bot_response: str):\n",
    "    global chat_history\n",
    "    \n",
    "    # Reset chat history if conversation goes off-topic\n",
    "    if classify_query_with_llm(user_query) == \"Irrelevant\":\n",
    "        chat_history = []\n",
    "\n",
    "    chat_history.append({\"user\": user_query, \"bot\": bot_response})\n",
    "\n",
    "# Function to generate SQL query using LLM\n",
    "def generate_sql_query(user_query: str):\n",
    "    prompt = f\"\"\"\n",
    "    You are an AI trained to generate SQL queries for a PostgreSQL database based on user input.\n",
    "    The database has a table named `restaurant_menu` with the following columns:\n",
    "    - `restaurant_name` (VARCHAR)\n",
    "    - `menu_category` (VARCHAR)\n",
    "    - `item_id` (INTEGER)\n",
    "    - `menu_item` (VARCHAR)\n",
    "    - `menu_description` (TEXT)\n",
    "    - `ingredient_name` (VARCHAR)\n",
    "    - `confidence` (FLOAT)\n",
    "    - `categories` (VARCHAR)\n",
    "    - `address1` (TEXT)\n",
    "    - `city` (VARCHAR)\n",
    "    - `zip_code` (VARCHAR)\n",
    "    - `country` (VARCHAR)\n",
    "    - `state` (VARCHAR)\n",
    "    - `rating` (VARCHAR)\n",
    "    - `review_count` (VARCHAR)\n",
    "    - `price` (VARCHAR)\n",
    "\n",
    "    Convert the following user query into a valid SQL query for the `restaurant_menu` table:\n",
    "    \"{user_query}\"\n",
    "\n",
    "    Only return the SQL query, no extra explanations, and do not include any code formatting markers.\n",
    "    Remember review_count, rating, and price columns are varchar. Perform cast conversion where necessary.\n",
    "    Don't forget to use DISTINCT as there are many duplicate restaurant names, ingredients, menu items etc.\n",
    "    Everything in the database is lower case, so remember to lowercase query values.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=100,\n",
    "    )\n",
    "    \n",
    "    return response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "\n",
    "# Function to execute SQL query\n",
    "def execute_sql_query(sql: str):\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        cursor.execute(sql)\n",
    "        results = cursor.fetchall()\n",
    "        if not results:\n",
    "            return \"No matching results found.\"\n",
    "        formatted_results = \"\\n\".join([\", \".join(map(str, row)) for row in results])\n",
    "        return formatted_results\n",
    "    except Exception as e:\n",
    "        return f\"Error executing query: {e}\"\n",
    "    finally:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "# Function to query restaurant database\n",
    "def query_restaurant_db(query: str, location: Optional[str]):\n",
    "    sql_query = generate_sql_query(query)\n",
    "    return execute_sql_query(sql_query)\n",
    "\n",
    "# Wikipedia search function\n",
    "def search_wikipedia(query: str):\n",
    "    try:\n",
    "        return wikipedia.summary(query, sentences=2)\n",
    "    except wikipedia.exceptions.PageError:\n",
    "        return \"No relevant Wikipedia article found.\"\n",
    "    except wikipedia.exceptions.DisambiguationError as e:\n",
    "        return f\"Did you mean: {', '.join(e.options[:5])}?\"\n",
    "\n",
    "# Google Search using SerpAPI\n",
    "def search_google(query: str):\n",
    "    google_search = SerpAPIWrapper(serpapi_api_key=SERPAPI_KEY)\n",
    "    return google_search.run(query)\n",
    "\n",
    "# LLM response function\n",
    "def generate_response(prompt: str):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful food assistant.\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "# Helper function to classify query using LLM\n",
    "def classify_query_with_llm(query: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    Classify the following query into one of the categories: Greeting, SQL, Wikipedia, GoogleSearch, Irrelevant.\n",
    "    \n",
    "    Query: {query}\n",
    "    Categories:\n",
    "    - Greeting: Greetings like \"Hello\", \"Hi\", \"Hey\", \"How are you?\", \"Good morning\", \"Good evening\", \"What can you do\".\n",
    "    - SQL: Queries that involve database searches, like finding restaurants, prices, or ratings.\n",
    "    - Wikipedia: Queries related to food items like sushi, food ingredients, cuisine history, nutrition, or similar background information.\n",
    "    - GoogleSearch: Queries asking for trending, popular, or recent food-related information, such as reviews or new restaurants.\n",
    "    - Irrelevant: If the query is about politics, violence, technology, sports, general knowledge, or anything unrelated to food or restaurants.\n",
    "    \n",
    "    Return only one of the categories: \"Greeting\", \"SQL\", \"Wikipedia\", \"GoogleSearch\", \"Irrelevant\" as string. Only the words.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=20,\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "\n",
    "\n",
    "@app.post(\"/chat/\")\n",
    "def chatbot(request: QueryRequest):\n",
    "    query = request.query.lower()\n",
    "    query_type = classify_query_with_llm(query)\n",
    "    \n",
    "    if query_type == \"Greeting\":\n",
    "        bot_response = \"Hello! Iâ€™m your restaurant and food assistant. You can ask me about restaurants, menus, food history, or reviews!\"\n",
    "    elif query_type == \"SQL\":\n",
    "        db_response = query_restaurant_db(query, request.location)\n",
    "        bot_response = generate_response(f\"User asked: {query}. Database says:\\n{db_response}\")\n",
    "    elif query_type == \"Wikipedia\":\n",
    "        wiki_info = search_wikipedia(query)\n",
    "        bot_response = generate_response(f\"User asked: {query}. Wikipedia info:\\n{wiki_info}\")\n",
    "    elif query_type == \"GoogleSearch\":\n",
    "        web_info = search_google(query)\n",
    "        bot_response = generate_response(f\"User asked: {query}. Web search results:\\n{web_info}\")\n",
    "    else:\n",
    "        bot_response = \"I can only answer food-related or restaurant queries.\"\n",
    "    \n",
    "    update_chat_history(query, bot_response)\n",
    "    \n",
    "    return {\"response\": bot_response}\n",
    "'''\n",
    "# Run the API on localhost\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(app, host=\"127.0.0.1\", port=8000)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
