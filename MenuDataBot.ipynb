{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d7e0347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import wikipedia\n",
    "import psycopg2\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import uvicorn\n",
    "from fastapi import FastAPI, HTTPException, Query, BackgroundTasks\n",
    "from pydantic import BaseModel\n",
    "from typing import Optional\n",
    "from langchain.tools import Tool\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "from requests import request\n",
    "import geocoder\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f656acf-04dd-45e4-bd9b-2ad57b5c8029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "_ = load_dotenv(dotenv_path=\"src/.env\")  # Read local .env file\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "DATABASE_URL = os.environ[\"DATABASE_URL\"]\n",
    "SERPAPI_KEY = os.environ[\"SERPAPI_KEY\"]  # For Google search\n",
    "\n",
    "# Initialize FastAPI\n",
    "app = FastAPI()\n",
    "\n",
    "# Database connection\n",
    "def get_db_connection():\n",
    "    return psycopg2.connect(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9ae06d3-9335-4410-9af1-a9f200189633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global list to store chat history as a list of dicts {\"user\": ..., \"bot\": ...}\n",
    "global chat_history\n",
    "chat_history = []\n",
    "\n",
    "# Helper function: return recent chat history as a string.\n",
    "# It takes the last two Q/A pairs and trims the string if it exceeds max_length.\n",
    "def get_recent_history(max_entries=2, max_length=512) -> str:\n",
    "    recent_entries = chat_history[-max_entries:]\n",
    "    history_str = \"\\n\".join([f\"User: {entry['user']}\\nBot: {entry['bot']}\" for entry in recent_entries])\n",
    "    if len(history_str) > max_length:\n",
    "        history_str = history_str[-max_length:]\n",
    "    return history_str\n",
    "\n",
    "# Update chat history and trim older interactions after 10 entries\n",
    "def update_chat_history(user_query: str, bot_response: str):\n",
    "    global chat_history\n",
    "    # If a greeting is detected, assume a new conversation and clear history\n",
    "    if classify_query_with_llm(user_query) == \"Greeting\":\n",
    "        chat_history = []\n",
    "    else:\n",
    "        chat_history.append({\"user\": user_query, \"bot\": bot_response})\n",
    "        # Archive older history by keeping only the last 10 interactions\n",
    "        if len(chat_history) > 10:\n",
    "            chat_history = chat_history[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc70213a-f20e-46d8-bff6-b8b1f8f6a113",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vishalbns/miniforge3/envs/genai/lib/python3.11/site-packages/pydantic/_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
      "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
     ]
    }
   ],
   "source": [
    "def load_and_store_pdf():\n",
    "    \"\"\"Loads the predefined PDF, extracts text, and stores embeddings in vector DB.\"\"\"\n",
    "    global vector_db\n",
    "\n",
    "    pdf_path = \"internal_docs/evolution_of_american_food.pdf\"  # Ensure this file is in your project directory\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    documents = loader.load()\n",
    "\n",
    "    # Split text into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "\n",
    "    # Generate embeddings using OpenAI\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "    # Store in in-memory vector database\n",
    "    vector_db = DocArrayInMemorySearch.from_documents(docs, embeddings)\n",
    "\n",
    "# Load the PDF on startup\n",
    "load_and_store_pdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bba9ef7-ab86-4f12-82dc-0141ac963ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate SQL query using LLM\n",
    "def generate_sql_query(user_query: str):\n",
    "    prompt = f\"\"\"\n",
    "    You are an AI trained to generate SQL queries for a PostgreSQL database based on user input.\n",
    "    The database has a table named `restaurant_menu` with the following columns:\n",
    "    - `restaurant_name` (VARCHAR)\n",
    "    - `menu_category` (VARCHAR)\n",
    "    - `item_id` (INTEGER)\n",
    "    - `menu_item` (VARCHAR)\n",
    "    - `menu_description` (TEXT)\n",
    "    - `ingredient_name` (VARCHAR)\n",
    "    - `confidence` (FLOAT)\n",
    "    - `categories` (VARCHAR)\n",
    "    - `address1` (TEXT)\n",
    "    - `city` (VARCHAR)\n",
    "    - `zip_code` (VARCHAR)\n",
    "    - `country` (VARCHAR)\n",
    "    - `state` (VARCHAR)\n",
    "    - `rating` (VARCHAR)\n",
    "    - `review_count` (VARCHAR)\n",
    "    - `price` (VARCHAR)\n",
    "\n",
    "    Convert the following user query into a valid SQL query for the `restaurant_menu` table:\n",
    "    \"{user_query}\"\n",
    "\n",
    "    Only return the SQL query, no extra explanations, and do not include any code formatting markers.\n",
    "    Remember review_count, rating, and price columns are varchar. Perform cast conversion where necessary.\n",
    "    Don't forget to use DISTINCT as there are many duplicate restaurant names, ingredients, menu items etc.\n",
    "    Everything in the database is lower case, so remember to lowercase query values.\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    max_tokens=100)\n",
    "\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# Function to execute SQL query\n",
    "def execute_sql_query(sql: str):\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        cursor.execute(sql)\n",
    "        results = cursor.fetchall()\n",
    "        if not results:\n",
    "            return \"No matching results found.\"\n",
    "        formatted_results = \"\\n\".join([\", \".join(map(str, row)) for row in results])\n",
    "        return formatted_results\n",
    "    except Exception as e:\n",
    "        return f\"Error executing query: {e}\"\n",
    "    finally:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "# Function to query restaurant database\n",
    "def query_restaurant_db(query: str):\n",
    "    sql_query = generate_sql_query(query)\n",
    "    return execute_sql_query(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f853bc63-205a-486e-86b2-38faf95ef418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wikipedia search function\n",
    "def search_wikipedia(query: str):\n",
    "    try:\n",
    "        return wikipedia.summary(query, sentences=2)\n",
    "    except wikipedia.exceptions.PageError:\n",
    "        return \"No relevant Wikipedia article found.\"\n",
    "    except wikipedia.exceptions.DisambiguationError as e:\n",
    "        return f\"Did you mean: {', '.join(e.options[:5])}?\"\n",
    "\n",
    "# Google Search using SerpAPI\n",
    "def search_google(query: str):\n",
    "    google_search = SerpAPIWrapper(serpapi_api_key=SERPAPI_KEY)\n",
    "    return google_search.run(query)\n",
    "\n",
    "\n",
    "def vector_db_search(query: str):\n",
    "    \"\"\"Retrieves relevant sections from the stored PDF based on user query.\"\"\"\n",
    "    if vector_db is None:\n",
    "        return {\"error\": \"VectorDB not initialized.\"}\n",
    "\n",
    "    retriever = vector_db.as_retriever()\n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\")  # Using GPT-3.5 Turbo for responses\n",
    "    chain = RetrievalQA.from_chain_type(llm, retriever=retriever)\n",
    "\n",
    "    response = chain.run(query)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "069bc6e8-fad7-43c5-aedb-48a7fd2d3cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM response function\n",
    "def generate_response(prompt: str):\n",
    "    prompt = f\"\"\" \n",
    "    Generate response for the prompt: {prompt}\n",
    "    You can refer to the chat history to provide answers only if the latest prompt is a follow up. \n",
    "    Do not apologise and do not mention any confusion unnecessarily.\n",
    "    Give a crisp, friendly, and polite response. If you are not sure, say you are not sure and advise reaching out to customer care.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful food assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "220f7474-fc41-43e4-8e8c-a0ead7809ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to classify query using LLM (with recent chat history included)\n",
    "def classify_query_with_llm(query: str) -> list:\n",
    "    # Include a brief recent history to help with follow-ups\n",
    "    prompt = f\"\"\"\n",
    "    New user query: \"{query}\"\n",
    "    Return a comma-separated list. There can be two classes.\n",
    "    Classify the query into one or more of the following categories: Greeting, SQL, Wikipedia, GoogleSearch, Irrelevant.\n",
    "    I have a database that has restaurant data with names of the restaurants, menu items, ingredients and addresses of the restaurant in San Francisco.\n",
    "    Categories:\n",
    "    - Greeting: Greetings like \"Hello\", \"Hi\", \"Hey\", \"How are you?\", \"Good morning\", \"Good evening\", \"What can you do\".\n",
    "    - VectorDBsearch: Query is about evolution of american food, thanksgiving, etc.\n",
    "    - SQL: Queries that involve database searches, like finding restaurants, prices, or ratings.\n",
    "    - Wikipedia: Queries related to food items like sushi, food ingredients, cuisine history, nutrition, or similar background information.\n",
    "    - GoogleSearch: Queries asking for trending, popular, or recent food-related information, such as reviews or new restaurants.\n",
    "    - Irrelevant: If the query is about politics, violence, technology, sports, general knowledge, or anything unrelated to food or restaurants.\n",
    "     Ex: \n",
    "    Query: \"What is the history of sushi, and which restaurants in my area are known for it?\"\n",
    "    Return \"Wikipedia\" and \"GoogleSearch\" both in the list.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    max_tokens=30)\n",
    "    categories = response.choices[0].message.content.strip()\n",
    "    return [cat.strip() for cat in categories.split(\",\") if cat.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d690469-15c8-4ae0-a639-56e58d175b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_follow_up_query(query, recent_history):\n",
    "    \"\"\"\n",
    "    Determines whether a given query is a follow-up to the recent chat history using an LLM.\n",
    "    \"\"\"\n",
    "    if not recent_history:\n",
    "        return False  # No history means no follow-up\n",
    "\n",
    "    follow_up_prompt = f\"\"\"\n",
    "    Chat history:\n",
    "    {recent_history}\n",
    "\n",
    "    New user query: \"{query}\"\n",
    "\n",
    "    Determine if the new query is a follow-up to the previous conversation.\n",
    "    If new query has phrases like \"list them\", \"give me its recipe\", etc. that talk about things in previous conversation, say \"Yes\",\n",
    "    If the new query seems independent and can do without previous conversation, say \"No\".\n",
    "    Respond with only one word: \"Yes\" or \"No\".\n",
    "    \"\"\"\n",
    "\n",
    "    follow_up_response = client.chat.completions.create(model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an intelligent assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": follow_up_prompt}\n",
    "    ],\n",
    "    max_tokens=5)\n",
    "\n",
    "    return follow_up_response.choices[0].message.content.strip().lower() == \"yes\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "760cb295-4089-4e54-a97b-7e7d425a7629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_to_db(query, location, query_types, bot_response):\n",
    "    try:\n",
    "        conn = get_db_connection()\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        insert_query = \"\"\"\n",
    "        INSERT INTO logs (time, location, query, category, response)\n",
    "        VALUES (%s, %s, %s, %s, %s)\n",
    "        \"\"\"\n",
    "        cursor.execute(insert_query, (datetime.now(), location, query, \", \".join(query_types), bot_response))\n",
    "\n",
    "        conn.commit()\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting into database: {e}\")\n",
    "    finally:\n",
    "        if cursor:\n",
    "            cursor.close()\n",
    "        if conn:\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d501750-2099-4eab-9cc0-45be819c1857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input model\n",
    "class QueryRequest(BaseModel):\n",
    "    query: str\n",
    "    location: Optional[str] = None  # For queries like \"near me\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "507d047f-87dc-47a9-80f9-e5db95096220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Run the API on localhost\\nif __name__ == \"__main__\":\\n    uvicorn.run(app, host=\"127.0.0.1\", port=8000)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@app.post(\"/chat/\")\n",
    "def chatbot(request: QueryRequest, background_tasks: BackgroundTasks):\n",
    "\n",
    "    query = request.query.lower()\n",
    "    recent_history = get_recent_history(max_entries=2, max_length=256)\n",
    "    is_follow_up = is_follow_up_query(query, recent_history)\n",
    "    combined_query = f\"{recent_history} {query}\" if is_follow_up else query\n",
    "\n",
    "    query_types = classify_query_with_llm(combined_query)\n",
    "    print(is_follow_up)\n",
    "    print(query_types)\n",
    "    print(combined_query)\n",
    "    location = geocoder.ip('me').address\n",
    "\n",
    "    # If the query is a greeting, clear history (new conversation) and respond without context.\n",
    "    if \"Greeting\" in query_types:\n",
    "        chat_history.clear()\n",
    "        bot_response = \"Hello! I’m your restaurant and food assistant. You can ask me about restaurants, menus, food history, or reviews!\"\n",
    "    else:\n",
    "        # Get recent history (if any) to include in the prompt for follow-up questions.\n",
    "        recent_history = get_recent_history(max_entries=2, max_length=512)\n",
    "        is_follow_up = is_follow_up_query(query, recent_history)\n",
    "        combined_query = f\"{recent_history} {query}\" if is_follow_up else query\n",
    "\n",
    "        query_types = classify_query_with_llm(combined_query)  # returns a list\n",
    "        bot_responses = []\n",
    "        \n",
    "        if \"VectorDBsearch\" in query_types:\n",
    "            bot_responses.append(vector_db_search(query))\n",
    "        \n",
    "        if \"SQL\" in query_types:\n",
    "            db_response = query_restaurant_db(combined_query)\n",
    "            full_prompt = (f\"Chat history:\\n{recent_history}\\nUser asked: {query}.\\nDatabase says:\\n{db_response}\") if is_follow_up else (f\"User asked: {query}.\\nDatabase says:\\n{db_response}\")\n",
    "            bot_responses.append(generate_response(full_prompt))\n",
    "\n",
    "        if \"Wikipedia\" in query_types:\n",
    "            wiki_query = combined_query[-300:] if len(combined_query) > 300 else combined_query\n",
    "            wiki_info = search_wikipedia(wiki_query)\n",
    "            full_prompt = (f\"Chat history:\\n{recent_history}\\nUser asked: {query}.\\nWikipedia info:\\n{wiki_info}\") if is_follow_up else (f\"User asked: {query}.\\nWikipedia info:\\n{wiki_info}\")\n",
    "            bot_responses.append(generate_response(full_prompt))\n",
    "\n",
    "        if \"GoogleSearch\" in query_types:\n",
    "            web_query = combined_query[-300:] if len(combined_query) > 300 else combined_query\n",
    "            if \"near me\" or \"my area\" in web_query.lower() and location:\n",
    "                web_query += f\"{location}\"\n",
    "            web_info = search_google(web_query)\n",
    "            full_prompt = (f\"Chat history:\\n{recent_history}\\nUser asked: {query}.\\nWeb search results:\\n{web_info}\") if is_follow_up else (f\"User asked: {query}.\\nWeb search results:\\n{web_info}\")\n",
    "            bot_responses.append(generate_response(full_prompt))\n",
    "\n",
    "        # Generate AI response based on combined results\n",
    "        if bot_responses:\n",
    "            full_prompt = f\"User asked: {query}\\n\\n\" + \"\\n\\n\".join(bot_responses)\n",
    "            bot_response = generate_response(full_prompt)\n",
    "        else:\n",
    "            bot_response = \"I can only answer food-related or restaurant queries.\"\n",
    "\n",
    "        update_chat_history(query, bot_response)\n",
    "\n",
    "    # Insert into database in background\n",
    "    background_tasks.add_task(insert_to_db, query, location, query_types, bot_response)\n",
    "\n",
    "    return {\"response\": bot_response}\n",
    "\n",
    "'''\n",
    "# Run the API on localhost\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(app, host=\"127.0.0.1\", port=8000)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2fda577a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wikipedia', 'GoogleSearch']\n"
     ]
    }
   ],
   "source": [
    "# Test the classification function\n",
    "prompt = \"What is the history of pizza, and which restaurants in my area are known for it?\"\n",
    "classes = classify_query_with_llm(prompt)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "050e1a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT COUNT(DISTINCT restaurant_name) \n",
      "FROM restaurant_menu \n",
      "WHERE city = 'san francisco' \n",
      "AND CAST(rating AS FLOAT) > 4.5;\n"
     ]
    }
   ],
   "source": [
    "# Test generate_sql_query function\n",
    "user_query = \"Find the number of best restaurants in San Francisco with a rating greater than 4.5\"\n",
    "sql_query = generate_sql_query(user_query)\n",
    "print(sql_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55f111fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "response = execute_sql_query(sql_query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c679a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT DISTINCT restaurant_name FROM restaurant_menu;\n"
     ]
    }
   ],
   "source": [
    "# Test generate_sql_query function\n",
    "user_query = \"List all the restaurants in the database\"\n",
    "sql_query = generate_sql_query(user_query)\n",
    "print(sql_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6c2c77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old jerusalem restaurant\n",
      "quik dog\n",
      "kahnfections\n",
      "20 spot\n",
      "heirloom cafe\n",
      "esperpento\n",
      "basa seafood express\n",
      "robin's cafe\n",
      "flour + water\n",
      "the sycamore\n",
      "kiwa kitchen\n",
      "belmar - la gallinita meat market\n",
      "3rd cousin\n",
      "lazy bear\n",
      "precita park cafe\n",
      "taishoken san francisco\n",
      "breakfast little\n",
      "seafood station\n",
      "boogaloos\n",
      "san ho won\n",
      "la oaxaqueña\n",
      "vegan mob\n",
      "the morris\n",
      "bac lieu restaurant\n",
      "rite spot cafe\n",
      "chili cha cha 2\n",
      "united dumplings\n",
      "the liberties\n",
      "foreign cinema\n",
      "blue plate\n",
      "tacos el patrón\n",
      "handroll project\n",
      "loltún restaurant\n",
      "tartine bakery\n",
      "good good culture club\n",
      "taco los altos\n",
      "cafe la taza\n",
      "antigua guatemala restaurant\n",
      "mi yucatan\n",
      "señor sisig\n",
      "taqueria vallarta\n",
      "etcetera wine bar\n",
      "chome\n",
      "regalito rosticeria\n",
      "taqueria cancún\n",
      "craftsman and wolves\n",
      "la espiga de oro\n",
      "al carajo\n",
      "sake bomb\n",
      "piglet & co\n",
      "chava's restaurant\n",
      "cafe gonzalez\n",
      "emmy's spaghetti shack\n",
      "ramenwell\n",
      "adam’s grub shack\n",
      "nonna's ristorante italiano\n",
      "cazuela comida mexicana\n",
      "foliage\n",
      "prubechu\n",
      "ko\n",
      "jake's steaks\n",
      "beretta valencia\n",
      "sanjalisco mexican restaurant\n",
      "el tomate restaurant\n",
      "coco's ramen\n",
      "echigo home cook\n",
      "china express & donut\n",
      "bao\n",
      "noodle girl\n",
      "wok & go\n",
      "frisco flavor\n",
      "fort point valencia\n",
      "district tea\n",
      "bernal star\n",
      "luisa's restaurant\n",
      "noeteca wine bar\n",
      "mission bowling club\n",
      "udupi palace\n",
      "wesburger 'n' more\n",
      "gyros and tzatziki\n",
      "taqueria el buen sabor\n",
      "tacolicious\n",
      "aedan koji kitchen\n",
      "indochine vegan\n",
      "lost resort\n",
      "yasmin\n",
      "four chairs\n",
      "petra mediterranean\n",
      "pho day\n",
      "al's super cafe\n",
      "cocina mamá cholita\n",
      "aramex\n",
      "chuy's fiestas\n",
      "destapas\n",
      "cha-ya san francisco\n",
      "true laurel\n",
      "moki's sushi & pacific grill\n",
      "los yaquis\n",
      "bobo's bistro\n",
      "el rey taquiza artesanal\n",
      "kazan\n",
      "fumi japanese curry & ramen\n",
      "kitava\n",
      "el buen comer\n",
      "valencia pizza & pasta\n",
      "bon, nene\n",
      "pinche sushi\n",
      "vega\n",
      "krispy krunchy chicken\n",
      "healthyish republic\n",
      "café de olla\n",
      "puerto alegre\n",
      "chuck's takeaway\n",
      "casa de la condesa restaurant\n",
      "la taqueria\n",
      "el fuego\n",
      "sushi hon\n",
      "dumpling story\n",
      "tadka indian restaurant\n",
      "stable cafe\n",
      "la palma mexicatessen\n",
      "el jacal mexican grill\n",
      "tinto\n",
      "the front porch\n",
      "mission curry house\n",
      "stonemill matcha\n",
      "beloved cafe\n",
      "raw sugar factory\n",
      "buddy\n",
      "nute's\n",
      "deccan house\n",
      "thanh tam ii\n",
      "sweet basil thai cuisine\n",
      "rasa rasa kitchen\n",
      "bandit dolores\n",
      "alnico\n",
      "chic n' time\n",
      "rosamunde sausage grill\n",
      "the spice jar\n",
      "j & e restaurant\n",
      "go duck yourself\n",
      "ernest\n",
      "tacos del barrio\n",
      "punjab restaurant\n",
      "la vaca birria\n",
      "yucatasia\n",
      "penny roma\n",
      "sidewalk juice\n",
      "el techo\n",
      "cuisine of nepal\n"
     ]
    }
   ],
   "source": [
    "response = execute_sql_query(sql_query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd16984d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Italian cuisine is a Mediterranean cuisine consisting of the ingredients, recipes, and cooking techniques developed in Italy since Roman times, and later spread around the world together with waves of Italian diaspora. Significant changes occurred with the colonization of the Americas and the introduction of potatoes, tomatoes, capsicums, maize, and sugar beet—the latter introduced in quantity in the 18th century.\n"
     ]
    }
   ],
   "source": [
    "# Test search_wikipedia function\n",
    "wiki_query = \"Italian cuisine\"\n",
    "wiki_response = search_wikipedia(wiki_query)\n",
    "print(wiki_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08fbac51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A vegan diet can offer several health benefits, including lower cholesterol levels, improved heart health, and better weight management. It may also reduce the risk of certain diseases like diabetes and certain types of cancer. Additionally, a plant-based diet is more sustainable for the environment and promotes animal welfare.\n"
     ]
    }
   ],
   "source": [
    "# Test generate_response function\n",
    "prompt = \"What are the benefits of a vegan diet?\"\n",
    "response = generate_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43525e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Best Pizza in Troy, MI - Crispelli's Bakery & Pizzeria, Peppy's Pizza-Subs & Bakery, Tru Pizza, Alibi, New York Pizza Pie, Grano Pizzaiolo, Loui's Pizza, ...\", 'Our Hayes Rd. location is famous for its speedy pizza carryout and delivery in Troy, Michigan. Order online or visit us today!', 'Find national chains, local Troy favorites, or new neighborhood restaurants, on Grubhub. Order online, and get Pizza delivery, or takeout, ...', \"Order pizza delivery & takeout in Troy. Call Domino's for pizza and food delivery in Troy. Order pizza, wings, sandwiches, salads, and more!\", \"At your Jet's on 5102 Rochester Rd, there's no doubt you will get a fast and fresh pizza that will exceed your wildest dreams.\", \"Your local Domino's pizza place in Troy delivers your favorite foods. Order online, through the Domino's app, or call (248) 689-8800 now!\", 'Looking for Pizza Delivery or Carryout? Browse all Pizza Hut locations in Troy, MI to find hot and fresh pizza, wings, pasta and more!', 'Address 987 Wilshire Dr Troy, MI 48084. Get Directions. Phone 248-516-0400. Hours. Sunday: 11:00AM - 8PM Monday: 11:00AM - 9PM Tuesday: 11:00AM - 9PM', 'Best Pizza in Troy, Michigan: Find Tripadvisor traveller reviews of Troy Pizza places and search by price, location, and more.', [{'position': 1, 'rating': 4.4, 'reviews': 1700, 'reviews_original': '(1.7K)', 'price': '$10–20', 'description': 'Thin-crust pies, Italian entrees, and baked goods in a casual setting with a bar and patio seating.', 'lsig': 'AB86z5WFHpq9JGUUyAtZD-7HwfEa', 'thumbnail': 'https://serpapi.com/searches/67a40788dd47a1ff0059727d/images/41e2a2defa46df0ea6dd90f495e5f4915aa566105ace1b339a05e7b2992e7fe02bc21373cbdacb86.jpeg', 'place_id': '5049510869055013722', 'place_id_search': 'https://serpapi.com/search.json?device=desktop&engine=google&gl=us&google_domain=google.com&hl=en&ludocid=5049510869055013722&q=Find+pizzerias+near+me', 'gps_coordinates': {'latitude': 42.563457, 'longitude': -83.135124}, 'title': \"Crispelli's Bakery & Pizzeria - Troy\", 'type': 'Pizza', 'address': '645 E Big Beaver Rd'}, {'position': 2, 'rating': 4.6, 'reviews': 71, 'reviews_original': '(71)', 'price': '$10–20', 'lsig': 'AB86z5VI6t5-tPbu_tKrxBCU89mA', 'thumbnail': 'https://serpapi.com/searches/67a40788dd47a1ff0059727d/images/41e2a2defa46df0ea6dd90f495e5f491a403091837841f0dfe2dc2c4aa67df01e5c0bffa76fab308.jpeg', 'service_options': {'dine_in': True, 'curbside_pickup': True, 'no_contact_delivery': True}, 'place_id': '5953972893955804595', 'place_id_search': 'https://serpapi.com/search.json?device=desktop&engine=google&gl=us&google_domain=google.com&hl=en&ludocid=5953972893955804595&q=Find+pizzerias+near+me', 'gps_coordinates': {'latitude': 42.54894, 'longitude': -83.16709}, 'title': 'Oven 360 Troy', 'type': 'Pizza', 'address': '1711 Crooks Rd'}, {'position': 3, 'rating': 4.3, 'reviews': 1500, 'reviews_original': '(1.5K)', 'price': '$10–20', 'description': 'Longtime stop for deep-dish pizza', 'lsig': 'AB86z5V_1Rb-nj1Z0mepMZoVpfqe', 'thumbnail': 'https://serpapi.com/searches/67a40788dd47a1ff0059727d/images/41e2a2defa46df0ea6dd90f495e5f4919fca46ba13e882936daca783d9f9c3debee2ced727012e3e.jpeg', 'place_id': '5506934064553184408', 'place_id_search': 'https://serpapi.com/search.json?device=desktop&engine=google&gl=us&google_domain=google.com&hl=en&ludocid=5506934064553184408&q=Find+pizzerias+near+me', 'gps_coordinates': {'latitude': 42.54834, 'longitude': -83.16793}, 'title': \"Shield's Restaurant Bar Pizzeria\", 'type': 'Pizza', 'address': '1476 W Maple Rd'}]]\n"
     ]
    }
   ],
   "source": [
    "# Test google search function\n",
    "google_query = \"Find pizzerias near me\"\n",
    "google_response = search_google(google_query)\n",
    "print(google_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880279d3-4bb6-4d31-8970-787a46774088",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
